{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original data into dataframe and check shape\n",
    "df_ori = pd.read_csv('dataset_diabetes/diabetic_data.csv')\n",
    "#print(df_ori.shape)\n",
    "df = df_ori.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1) #should we code it into 1 and 2?\n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "5        Caucasian    Male  [50-60)                  2   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "5                         1                    2                 3   \n",
       "\n",
       "   num_lab_procedures  num_procedures  num_medications  ...  tolazamide  \\\n",
       "1                  59               0               18  ...          No   \n",
       "2                  11               5               13  ...          No   \n",
       "3                  44               1               16  ...          No   \n",
       "4                  51               0                8  ...          No   \n",
       "5                  31               6               16  ...          No   \n",
       "\n",
       "   insulin  glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
       "1       Up                   No                  No                       No   \n",
       "2       No                   No                  No                       No   \n",
       "3       Up                   No                  No                       No   \n",
       "4   Steady                   No                  No                       No   \n",
       "5   Steady                   No                  No                       No   \n",
       "\n",
       "  metformin-rosiglitazone  metformin-pioglitazone change diabetesMed  \\\n",
       "1                      No                      No     Ch         Yes   \n",
       "2                      No                      No     No         Yes   \n",
       "3                      No                      No     Ch         Yes   \n",
       "4                      No                      No     Ch         Yes   \n",
       "5                      No                      No     No         Yes   \n",
       "\n",
       "  readmitted  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['patient_nbr','citoglipton','weight','examide','encounter_id', 'medical_specialty', 'payer_code'],inplace=True)\n",
    "#df.drop(columns = ['citoglipton','weight','examide','encounter_id', 'medical_specialty', 'payer_code'],inplace=True)\n",
    "\n",
    "#df = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\n",
    "drop_Idx = set()\n",
    "drop_Idx = drop_Idx.union(set(df[df['discharge_disposition_id'] == 11].index))\n",
    "drop_Idx = drop_Idx.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_1'][df['diag_1']=='?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_2'][df['diag_2']=='?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_3'][df['diag_3']=='?'].index))\n",
    "new_Idx = list(set(df.index) - set(drop_Idx))\n",
    "df = df.iloc[new_Idx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', \n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', \n",
    "        'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', \n",
    "        'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "\n",
    "for col in keys:\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)\n",
    "    \n",
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "\n",
    "df['age'] = df['age'].replace('[0-10)', 5)\n",
    "df['age'] = df['age'].replace('[10-20)', 15)\n",
    "df['age'] = df['age'].replace('[20-30)', 25)\n",
    "df['age'] = df['age'].replace('[30-40)', 35)\n",
    "df['age'] = df['age'].replace('[40-50)', 45)\n",
    "df['age'] = df['age'].replace('[50-60)', 55)\n",
    "df['age'] = df['age'].replace('[60-70)', 65)\n",
    "df['age'] = df['age'].replace('[70-80)', 75)\n",
    "df['age'] = df['age'].replace('[80-90)', 85)\n",
    "df['age'] = df['age'].replace('[90-100)', 95)\n",
    "\n",
    "df['race'] = df['race'].replace('Caucasian', 0)\n",
    "df['race'] = df['race'].replace('AfricanAmerican', 1)\n",
    "df['race'] = df['race'].replace('Hispanic', 2)\n",
    "df['race'] = df['race'].replace('Asian', 3)\n",
    "df['race'] = df['race'].replace('Other', 4)\n",
    "\n",
    "df = df.replace('?', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags = ['diag_1','diag_2','diag_3']\n",
    "    \n",
    "def detection(value):\n",
    "    if value[0]== \"V\" or value[0] == 'E':\n",
    "        value = '0'\n",
    "        return value # from new york united healthcare\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "for f in diags:\n",
    "    for i in df[f].index:\n",
    "        df[f].at[i] = detection(df[f].at[i])\n",
    "        \n",
    "for i in df['diag_1']:\n",
    "    b = 'V' in str(i)\n",
    "    c = 'E' in str(i)\n",
    "    if b or c:\n",
    "        print(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geelo  Index(['race', 'gender', 'age', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
      "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'service_utilization'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['race', 'gender', 'age', 'admission_type_id',\n",
       "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
       "       'num_lab_procedures', 'num_procedures', 'num_medications', 'diag_1',\n",
       "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
       "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
       "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
       "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
       "       'service_utilization'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
    "print(\"geelo \", df.columns)\n",
    "df.drop(['number_outpatient', 'number_emergency', 'number_inpatient'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_glu_serum = pd.get_dummies(df['max_glu_serum'])\n",
    "df_A1Cresult = pd.get_dummies(df['A1Cresult'])\n",
    "df_insulin = pd.get_dummies(df['insulin'])\n",
    "df_discharge_disposition_id = pd.get_dummies(df['discharge_disposition_id'])\n",
    "df_admission_source_id = pd.get_dummies(df['admission_source_id'])\n",
    "df_admission_type_id = pd.get_dummies(df['admission_type_id'])\n",
    "\n",
    "      \n",
    "df = pd.concat([df,df_max_glu_serum, df_A1Cresult, \n",
    "                df_insulin, df_discharge_disposition_id, \n",
    "                df_admission_source_id, df_admission_type_id], axis=1)\n",
    "df.drop([ 'max_glu_serum', 'A1Cresult', 'insulin','discharge_disposition_id', 'admission_source_id', \n",
    "                  'admission_type_id'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_col_names = df.columns\n",
    "x = df[feature_col_names]\n",
    "x = df.loc[:, df.columns != 'readmitted']\n",
    "y = df['readmitted']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 87351, 1: 11250})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lillian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape Counter({0: 87351, 1: 87351})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_sample(x.as_matrix(), y)\n",
    "print('New dataset shape {}'.format(Counter(train_output_new)))\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(x.columns))\n",
    "Xtr, Xva, Ytr, Yva = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score:   0.52810869985189\n",
      "Validation Accuracy Score:   0.5225666122892877\n"
     ]
    }
   ],
   "source": [
    "y_train_preds = clf.predict(Xtr)\n",
    "y_valid_preds = clf.predict(Xva)\n",
    "\n",
    "print(\"Training Accuracy Score:  \", accuracy_score(Ytr, y_train_preds ))\n",
    "print(\"Validation Accuracy Score:  \", accuracy_score(Yva, y_valid_preds ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding optimal number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  layers\n",
      "Training Accuracy Score:   0.5006904644357153\n",
      "Validation Accuracy Score:   0.49718096219341174\n",
      "\n",
      "50  layers\n",
      "Training Accuracy Score:   0.6136833594493457\n",
      "Validation Accuracy Score:   0.611945851578375\n",
      "\n",
      "100  layers\n",
      "Training Accuracy Score:   0.6370518241855739\n",
      "Validation Accuracy Score:   0.6316075670415844\n",
      "\n",
      "200  layers\n",
      "Training Accuracy Score:   0.7835948512102804\n",
      "Validation Accuracy Score:   0.7803440084714233\n",
      "\n",
      "300  layers\n",
      "Training Accuracy Score:   0.6564706892480735\n",
      "Validation Accuracy Score:   0.6506682693683639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers = np.array([1, 50, 100, 200, 300])\n",
    "\n",
    "for l in layers:\n",
    "    nn = MLPClassifier(hidden_layer_sizes = (l,), max_iter = 400)\n",
    "    nn.fit(Xtr, Ytr)\n",
    "\n",
    "    y_train_preds = nn.predict(Xtr)\n",
    "    y_valid_preds = nn.predict(Xva)\n",
    "    \n",
    "    print(l, \" layers\")\n",
    "    print(\"Training Accuracy Score:  \", accuracy_score(Ytr, y_train_preds ))\n",
    "    print(\"Validation Accuracy Score:  \", accuracy_score(Yva, y_valid_preds ))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "identity\n",
      "Training Accuracy Score:   0.5169467877304827\n",
      "Validation Accuracy Score:   0.5130076414527346\n",
      "\n",
      "logistic\n",
      "Training Accuracy Score:   0.7651848512818311\n",
      "Validation Accuracy Score:   0.7608826307203572\n",
      "\n",
      "tanh\n",
      "Training Accuracy Score:   0.6741150964861442\n",
      "Validation Accuracy Score:   0.6763401161958731\n",
      "\n",
      "relu\n",
      "Training Accuracy Score:   0.663990669786278\n",
      "Validation Accuracy Score:   0.6633467845797201\n"
     ]
    }
   ],
   "source": [
    "functions = np.array([\"identity\", \"logistic\", \"tanh\", \"relu\"])\n",
    "for f in functions:\n",
    "\n",
    "    nn = MLPClassifier(hidden_layer_sizes = (200,), activation = f)\n",
    "    nn.fit(Xtr, Ytr)\n",
    "\n",
    "    y_train_preds = nn.predict(Xtr)\n",
    "    y_valid_preds = nn.predict(Xva)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f)\n",
    "    print(\"Training Accuracy Score:  \", accuracy_score(Ytr, y_train_preds ))\n",
    "    print(\"Validation Accuracy Score:  \", accuracy_score(Yva, y_valid_preds ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Neural Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score:   0.7755954808566052\n",
      "Validation Accuracy Score:   0.7727311754099768\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes = (200,), activation = \"logistic\")\n",
    "nn.fit(Xtr, Ytr)\n",
    "\n",
    "y_train_preds = nn.predict(Xtr)\n",
    "y_valid_preds = nn.predict(Xva)\n",
    "\n",
    "print(\"Training Accuracy Score:  \", accuracy_score(Ytr, y_train_preds ))\n",
    "print(\"Validation Accuracy Score:  \", accuracy_score(Yva, y_valid_preds ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "results = cross_val_score(nn, x, y, cv=10)\n",
    "avg = results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8860254967990155\n"
     ]
    }
   ],
   "source": [
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score:   0.6070148324639921\n",
      "Validation Accuracy Score:   0.598008070747832\n"
     ]
    }
   ],
   "source": [
    "nn1 = MLPClassifier(hidden_layer_sizes = (100,), activation = \"relu\")\n",
    "nn1.fit(Xtr, Ytr)\n",
    "\n",
    "y_train_preds = nn1.predict(Xtr)\n",
    "y_valid_preds = nn1.predict(Xva)\n",
    "\n",
    "print(\"Training Accuracy Score:  \", accuracy_score(Ytr, y_train_preds ))\n",
    "print(\"Validation Accuracy Score:  \", accuracy_score(Yva, y_valid_preds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8859240769207192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "results = cross_val_score(nn, x, y, cv=10)\n",
    "avg = results.mean()\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "After testing these parameters, it is found that the optimal amount of hidden layers is 200 and the optimal activation function is the logistic (sigmoid) function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
