{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 2 3 4 5 8 7]\n"
     ]
    }
   ],
   "source": [
    "df_ori = pd.read_csv('diabetic_data.csv')\n",
    "df = df_ori.copy(deep=True)\n",
    "\n",
    "print(df['admission_type_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # getting a peek at what our data looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING INTRODUCTORY STATISTICS ABOUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 50)\n",
      "encounter_id                 int64\n",
      "patient_nbr                  int64\n",
      "race                        object\n",
      "gender                      object\n",
      "age                         object\n",
      "weight                      object\n",
      "admission_type_id            int64\n",
      "discharge_disposition_id     int64\n",
      "admission_source_id          int64\n",
      "time_in_hospital             int64\n",
      "payer_code                  object\n",
      "medical_specialty           object\n",
      "num_lab_procedures           int64\n",
      "num_procedures               int64\n",
      "num_medications              int64\n",
      "number_outpatient            int64\n",
      "number_emergency             int64\n",
      "number_inpatient             int64\n",
      "diag_1                      object\n",
      "diag_2                      object\n",
      "diag_3                      object\n",
      "number_diagnoses             int64\n",
      "max_glu_serum               object\n",
      "A1Cresult                   object\n",
      "metformin                   object\n",
      "repaglinide                 object\n",
      "nateglinide                 object\n",
      "chlorpropamide              object\n",
      "glimepiride                 object\n",
      "acetohexamide               object\n",
      "glipizide                   object\n",
      "glyburide                   object\n",
      "tolbutamide                 object\n",
      "pioglitazone                object\n",
      "rosiglitazone               object\n",
      "acarbose                    object\n",
      "miglitol                    object\n",
      "troglitazone                object\n",
      "tolazamide                  object\n",
      "examide                     object\n",
      "citoglipton                 object\n",
      "insulin                     object\n",
      "glyburide-metformin         object\n",
      "glipizide-metformin         object\n",
      "glimepiride-pioglitazone    object\n",
      "metformin-rosiglitazone     object\n",
      "metformin-pioglitazone      object\n",
      "change                      object\n",
      "diabetesMed                 object\n",
      "readmitted                  object\n",
      "dtype: object\n",
      "readmitted\n",
      "<30    11357\n",
      ">30    35545\n",
      "NO     54864\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) # figuring out how many features there are[1], how many records[0]\n",
    "print(df.dtypes)# important to know what is the data type of each feature\n",
    "for x in df.columns: # figuring out how to get all possible unique values of each feature\n",
    "    print(x, df[x].unique())\n",
    "class_counts = df.groupby('readmitted').size() #figuring out the size of each class label group\n",
    "# how many are 'readmitted', '<30', '>30'\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKEWS\n",
      "encounter_id                 0.699142\n",
      "patient_nbr                  0.471281\n",
      "admission_type_id            1.591984\n",
      "discharge_disposition_id     2.563067\n",
      "admission_source_id          1.029935\n",
      "time_in_hospital             1.133999\n",
      "num_lab_procedures          -0.236544\n",
      "num_procedures               1.316415\n",
      "num_medications              1.326672\n",
      "number_outpatient            8.832959\n",
      "number_emergency            22.855582\n",
      "number_inpatient             3.614139\n",
      "number_diagnoses            -0.876746\n",
      "dtype: float64\n",
      "0         0.000409\n",
      "1         0.003678\n",
      "2         0.002452\n",
      "3         0.002861\n",
      "4         0.002043\n",
      "            ...   \n",
      "101761    0.003678\n",
      "101762    0.003678\n",
      "101763    0.005313\n",
      "101764    0.003678\n",
      "101765    0.003678\n",
      "Name: number_diagnoses, Length: 101766, dtype: float64\n",
      "SKEWS---Normalized\n",
      "0        -3.321596\n",
      "1         0.815784\n",
      "2        -0.735733\n",
      "3        -0.218561\n",
      "4        -1.252906\n",
      "            ...   \n",
      "101761    0.815784\n",
      "101762    0.815784\n",
      "101763    2.884475\n",
      "101764    0.815784\n",
      "101765    0.815784\n",
      "Name: number_diagnoses, Length: 101766, dtype: float64\n",
      "encounter_id                 0.699142\n",
      "patient_nbr                  0.471281\n",
      "admission_type_id            1.591984\n",
      "discharge_disposition_id     2.563067\n",
      "admission_source_id          1.029935\n",
      "time_in_hospital             1.133999\n",
      "num_lab_procedures          -0.236544\n",
      "num_procedures               1.316415\n",
      "num_medications              1.326672\n",
      "number_outpatient            8.832959\n",
      "number_emergency            22.855582\n",
      "number_inpatient             3.614139\n",
      "number_diagnoses            -0.876746\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.width', 100)\n",
    "# pd.set_option('precision', 3)\n",
    "# correlations = df.corr(method='pearson')\n",
    "# print(correlations) \n",
    "dfcopy = df_ori.copy(deep=True)\n",
    "numerics = ['encounter_id', 'patient_nbr', 'admission_type_id', 'discharge_disposition_id',\n",
    "           'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', \n",
    "           'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient',\n",
    "            'number_diagnoses']\n",
    "\n",
    "print(\"SKEWS\")\n",
    "skew = df.skew()\n",
    "#print(df.head())\n",
    "print(skew) \n",
    "print(df['number_diagnoses'])\n",
    "from sklearn.preprocessing import Normalizer\n",
    "X = dfcopy[numerics].values\n",
    "for x in numerics:\n",
    "    scaler = Normalizer().fit()\n",
    "    normalizedX = scaler.transform([dfcopy[x]])\n",
    "#     #print(normalizedX\n",
    "#     print(dfcopy[x].size, normalizedX.size)\n",
    "#     print(dfcopy[x])\n",
    "#     dfcopy[x] = normalizedX\n",
    "\n",
    "def standardize(raw_data):\n",
    "    return ((raw_data - np.mean(raw_data, axis = 0)) / np.std(raw_data, axis = 0))\n",
    "dfcopy[numerics] = standardize(dfcopy[numerics])\n",
    "\n",
    "print(\"SKEWS---Normalized\")\n",
    "print(dfcopy['number_diagnoses'])\n",
    "skew = dfcopy.skew()\n",
    "#print(df.head())\n",
    "print(skew) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist() # getting histograms to view data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is kind of like histograms but it was easier to tell here if there \n",
    "# is a skew in the data. Some machine learners assume that the features\n",
    "# are already in a Gaussian distribution - machine learning mastery with python\n",
    "df.plot(kind='density', subplots=True, layout=(6,6), sharex=False) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plot, shows the mean and std deviation - may DELETE\n",
    "df.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if some data are correlated with each other, then adjusting one may\n",
    "# affect the other, this is something to keep in mind\n",
    "\n",
    "correlations = df.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is another way of showing correlation - may take out this or heatmap\n",
    "# from pandas.plotting import scatter_matrix\n",
    "# scatter_matrix(df)\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "         print(col,df[col][df[col] == '?'].count())\n",
    "\n",
    "print('gender', df['gender'][df['gender'] == 'Unknown/Invalid'].count())\n",
    "\n",
    "#taken from: https://medium.com/berkeleyischool/how-to-use-machine-learning-to-predict-hospital-readmissions-part-1-bd137cbdba07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping missing values from above cell\n",
    "#after taking a closer look at the data, patient_nbr, encounter_id are not \n",
    "#really adding to the analysis, they are unique numbers for the patient - EDIT later\n",
    "#all the values of citoglipton and examide are the same\n",
    "df.drop(columns = ['patient_nbr','citoglipton','weight','examide','encounter_id', 'medical_specialty', 'payer_code'],inplace=True)\n",
    "#df.drop(columns = ['citoglipton','weight','examide','encounter_id', 'medical_specialty', 'payer_code'],inplace=True)\n",
    "\n",
    "#df = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\n",
    "drop_Idx = set()\n",
    "drop_Idx = drop_Idx.union(set(df[df['discharge_disposition_id'] == 11].index))\n",
    "drop_Idx = drop_Idx.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_1'][df['diag_1']=='?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_2'][df['diag_2']=='?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_3'][df['diag_3']=='?'].index))\n",
    "new_Idx = list(set(df.index) - set(drop_Idx))\n",
    "df = df.iloc[new_Idx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replaced these because we tried running the learners on the data\n",
    "#and errors kept popping up bc they could not process strings\n",
    "df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1) #should we code it into 1 and 2?\n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)\n",
    "df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', \n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', \n",
    "        'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', \n",
    "        'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "\n",
    "for col in keys:\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)\n",
    "    \n",
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "\n",
    "df['age'] = df['age'].replace('[0-10)', 5)\n",
    "df['age'] = df['age'].replace('[10-20)', 15)\n",
    "df['age'] = df['age'].replace('[20-30)', 25)\n",
    "df['age'] = df['age'].replace('[30-40)', 35)\n",
    "df['age'] = df['age'].replace('[40-50)', 45)\n",
    "df['age'] = df['age'].replace('[50-60)', 55)\n",
    "df['age'] = df['age'].replace('[60-70)', 65)\n",
    "df['age'] = df['age'].replace('[70-80)', 75)\n",
    "df['age'] = df['age'].replace('[80-90)', 85)\n",
    "df['age'] = df['age'].replace('[90-100)', 95)\n",
    "\n",
    "df['race'] = df['race'].replace('Caucasian', 0)\n",
    "df['race'] = df['race'].replace('AfricanAmerican', 1)\n",
    "df['race'] = df['race'].replace('Hispanic', 2)\n",
    "df['race'] = df['race'].replace('Asian', 3)\n",
    "df['race'] = df['race'].replace('Other', 4)\n",
    "\n",
    "# if there are any more missing values, replace them with -1\n",
    "df = df.replace('?', -1)\n",
    "\n",
    "for col in df:\n",
    "    print(col, \" : \")\n",
    "    print(df[col].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[(df.diag_1.str.contains('V')),'diag_1']=0\n",
    "# df.loc[(df.diag_1.str.contains('E')),'diag_1']=0\n",
    "\n",
    "# df.loc[(df.diag_2.str.contains('V')),'diag_2']=0\n",
    "# df.loc[(df.diag_2.str.contains('E')),'diag_2']=0\n",
    "\n",
    "# df.loc[(df.diag_3.str.contains('V')),'diag_3']=0\n",
    "# df.loc[(df.diag_3.str.contains('E')),'diag_3']=0\n",
    "\n",
    "# for i in df['diag_1']:\n",
    "#     b = 'V' in str(i)\n",
    "#     c = 'E' in str(i)\n",
    "#     if b or c:\n",
    "#         print(str(i))\n",
    "        \n",
    "        \n",
    "# for i in df['diag_2']:\n",
    "#     b = 'V' in str(i)\n",
    "#     c = 'E' in str(i)\n",
    "#     if b or c:\n",
    "#         print(str(i))\n",
    "        \n",
    "        \n",
    "# for i in df['diag_3']:\n",
    "#     b = 'V' in str(i)\n",
    "#     c = 'E' in str(i)\n",
    "#     if b or c:\n",
    "#         print(str(i))\n",
    "\n",
    "diags = ['diag_1','diag_2','diag_3']\n",
    "    \n",
    "def detection(value):\n",
    "    if value[0]== \"V\" or value[0] == 'E':\n",
    "        value = '0'\n",
    "        return value # from new york united healthcare\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "for f in diags:\n",
    "    for i in df[f].index:\n",
    "        df[f].at[i] = detection(df[f].at[i])\n",
    "        \n",
    "for i in df['diag_1']:\n",
    "    b = 'V' in str(i)\n",
    "    c = 'E' in str(i)\n",
    "    if b or c:\n",
    "        print(str(i))\n",
    "        \n",
    "#print(df['diag_1'].unique())\n",
    "        \n",
    "#print(df['diag_2'].unique())\n",
    "        \n",
    "#print(df['diag_3'].unique())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
    "#print(\"geelo \", df.columns)\n",
    "df.drop(['number_outpatient', 'number_emergency', 'number_inpatient'], axis=1, inplace=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_age = pd.get_dummies(df['age'])\n",
    "#df_race = pd.get_dummies(df['race'])\n",
    "#df_gender = pd.get_dummies(df['gender'])\n",
    "#df_change = pd.get_dummies(df['change'])\n",
    "#df_diabetesMed = pd.get_dummies(df['diabetesMed'])\n",
    "\n",
    "df_max_glu_serum = pd.get_dummies(df['max_glu_serum'])\n",
    "df_A1Cresult = pd.get_dummies(df['A1Cresult'])\n",
    "df_insulin = pd.get_dummies(df['insulin'])\n",
    "df_discharge_disposition_id = pd.get_dummies(df['discharge_disposition_id'])\n",
    "df_admission_source_id = pd.get_dummies(df['admission_source_id'])\n",
    "df_admission_type_id = pd.get_dummies(df['admission_type_id'])\n",
    "\n",
    "#print(df_max_glu_serum)\n",
    "#df = pd.concat([df,df_max_glu_serum])\n",
    "#df.drop(['max_glu_serum'], axis=1, inplace=True)             \n",
    "df = pd.concat([df,df_max_glu_serum, df_A1Cresult, \n",
    "                df_insulin, df_discharge_disposition_id, \n",
    "                df_admission_source_id, df_admission_type_id], axis=1)\n",
    "df.drop([ 'max_glu_serum', 'A1Cresult', 'insulin','discharge_disposition_id', 'admission_source_id', \n",
    "                  'admission_type_id'], axis=1, inplace=True)\n",
    "#before\n",
    "df.groupby('readmitted').size().plot(kind='bar')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(df.shape)\n",
    "# df = df['readmitted' == 1 or 'readmitted' == 0]\n",
    "#df.readmitted = np.where(df.readmitted=2, 0, df.readmitted)\n",
    "#after\n",
    "# df.groupby('readmitted').size().plot(kind='bar')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title(\"AFTER CHANGE\")\n",
    "# plt.show()\n",
    "# #print(df.iloc[0])\n",
    "# #df.head()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "# rescaling data to get all features on the same scale\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "# get mean of 0 and std of 1\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "# normalize - \n",
    "# 'For machine learning, every dataset does not require normalization. \n",
    "# It is required only when features have different ranges.'\n",
    "# : taken from https://medium.com/@swethalakshmanan14/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to prevent overfitting - data split, cross validation, bootstrap?\n",
    "# taken from: https://stats.stackexchange.com/questions/81576/how-to-judge-if-a-supervised-machine-learning-model-is-overfitting-or-not\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
