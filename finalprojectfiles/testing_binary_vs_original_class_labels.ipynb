{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv('diabetic_data.csv')\n",
    "df = df_ori.copy(deep=True)\n",
    "#for x in df.columns:\n",
    "#    print(x, df[x].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape)\n",
    "# print(df.dtypes)\n",
    "# class_counts = df.groupby('readmitted').size() \n",
    "# print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.set_option('display.width', 100)\n",
    "# # pd.set_option('precision', 3)\n",
    "# # correlations = df.corr(method='pearson')\n",
    "# # print(correlations) \n",
    "# dfcopy = df_ori.copy(deep=True)\n",
    "numerics = ['encounter_id', 'patient_nbr', 'admission_type_id', 'discharge_disposition_id',\n",
    "           'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', \n",
    "           'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient',\n",
    "            'number_diagnoses']\n",
    "\n",
    "others = [col for col in df.columns if col not in numerics]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_num = scaler.fit_transform(df[numerics])\n",
    "x_all = np.concatenate([x_num, df[others].values], axis =1)\n",
    "\n",
    "df_copy = pd.DataFrame(data=x_all, columns=numerics+others)\n",
    "\n",
    "#print(df_copy['race'])\n",
    "# print(\"SKEWS\")\n",
    "# skew = df.skew()\n",
    "# #print(df.head())\n",
    "# print(skew) \n",
    "# print(df['number_diagnoses'])\n",
    "\n",
    "# #using minmax scaler does not take away skew\n",
    "\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# for x in numerics:\n",
    "#     dfcopy[x] = minmax_scale(dfcopy[x])\n",
    "# print(\"SKEWS -- minmax\")    \n",
    "# skew = dfcopy.skew()\n",
    "# print(skew) \n",
    "# print(dfcopy['number_diagnoses'])\n",
    "# # print(df['number_diagnoses'])\n",
    "# # from sklearn.preprocessing import Normalizer\n",
    "# # X = dfcopy[numerics].values\n",
    "# # for x in numerics:\n",
    "# #     scaler = Normalizer().fit()\n",
    "# #     normalizedX = scaler.transform([dfcopy[x]])\n",
    "# # #     #print(normalizedX\n",
    "# # #     print(dfcopy[x].size, normalizedX.size)\n",
    "# # #     print(dfcopy[x])\n",
    "# # #     dfcopy[x] = normalizedX\n",
    "\n",
    "# # def standardize(raw_data):\n",
    "# #     return ((raw_data - np.mean(raw_data, axis = 0)) / np.std(raw_data, axis = 0))\n",
    "# # dfcopy[numerics] = standardize(dfcopy[numerics])\n",
    "\n",
    "# # print(\"SKEWS---Normalized\")\n",
    "# # print(dfcopy['number_diagnoses'])\n",
    "# # skew = dfcopy.skew()\n",
    "# # #print(df.head())\n",
    "# # print(skew) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(kind='density', subplots=True, layout=(6,6), sharex=False) \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False) \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = df.corr()\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "# fig.colorbar(cax)\n",
    "# plt.show() \n",
    "\n",
    "# from pandas.plotting import scatter_matrix\n",
    "# scatter_matrix(df)\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "# df['readmitted'] = df['readmitted'].replace('<30', 1) #should we code it into 1 and 2?\n",
    "# df['readmitted'] = df['readmitted'].replace('NO', 0)\n",
    "# df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "5        Caucasian    Male  [50-60)                  2   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "5                         1                    2                 3   \n",
       "\n",
       "   num_lab_procedures  num_procedures  num_medications  ...  tolazamide  \\\n",
       "1                  59               0               18  ...          No   \n",
       "2                  11               5               13  ...          No   \n",
       "3                  44               1               16  ...          No   \n",
       "4                  51               0                8  ...          No   \n",
       "5                  31               6               16  ...          No   \n",
       "\n",
       "   insulin  glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
       "1       Up                   No                  No                       No   \n",
       "2       No                   No                  No                       No   \n",
       "3       Up                   No                  No                       No   \n",
       "4   Steady                   No                  No                       No   \n",
       "5   Steady                   No                  No                       No   \n",
       "\n",
       "  metformin-rosiglitazone  metformin-pioglitazone change diabetesMed  \\\n",
       "1                      No                      No     Ch         Yes   \n",
       "2                      No                      No     No         Yes   \n",
       "3                      No                      No     Ch         Yes   \n",
       "4                      No                      No     Ch         Yes   \n",
       "5                      No                      No     No         Yes   \n",
       "\n",
       "  readmitted  \n",
       "1        >30  \n",
       "2         NO  \n",
       "3         NO  \n",
       "4         NO  \n",
       "5        >30  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['patient_nbr','citoglipton','weight','examide','encounter_id', 'medical_specialty', 'payer_code'],inplace=True)\n",
    "#df.drop(columns = ['citoglipton','weight','examide','encounter_id', 'medical_specialty', 'payer_code'],inplace=True)\n",
    "\n",
    "#df = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\n",
    "drop_Idx = set()\n",
    "drop_Idx = drop_Idx.union(set(df[df['discharge_disposition_id'] == 11].index))\n",
    "drop_Idx = drop_Idx.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_1'][df['diag_1']=='?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_2'][df['diag_2']=='?'].index))\n",
    "drop_Idx = drop_Idx.union(set(df['diag_3'][df['diag_3']=='?'].index))\n",
    "new_Idx = list(set(df.index) - set(drop_Idx))\n",
    "df = df.iloc[new_Idx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race  : \n",
      "[ 0  1 -1  4  3  2]\n",
      "gender  : \n",
      "[0 1]\n",
      "age  : \n",
      "[15 25 35 45 55 65 75 85 95  5]\n",
      "admission_type_id  : \n",
      "[1 2 3 6 4 5 8 7]\n",
      "discharge_disposition_id  : \n",
      "[ 1  3  6  2  5  7 25 10  4 14 18  8 13 12 16 17 22 23  9 20 15 24 28 19\n",
      " 27]\n",
      "admission_source_id  : \n",
      "[ 7  2  4  1  5 20  6  3 17  8  9 14 10 22 11 25 13]\n",
      "time_in_hospital  : \n",
      "[ 3  2  1  4  5 13 12  9  7 10  6 11  8 14]\n",
      "num_lab_procedures  : \n",
      "[ 59  11  44  51  31  70  73  68  33  47  62  60  55  49  75  45  29  35\n",
      "  42  66  36  19  64  25  53  52  87  27  37  41  28  48  10   2  65  67\n",
      "  40  54  58  57  43  32  83  34  39  69  38  72  22  96  46  78  56  61\n",
      "  88  50   1  18  82   9  63  24  71  77  81  76  90  93   3 103  13  80\n",
      "  85  16  15  12  30  23  17  21  79  26   5  95  97  84  14  74 105  86\n",
      "  98  20   6  94   8 102   7  89  91  92   4 101  99 100 114 113 111 129\n",
      " 107 108 106 104 109 120 132 121 126 118]\n",
      "num_procedures  : \n",
      "[0 5 1 6 2 3 4]\n",
      "num_medications  : \n",
      "[18 13 16  8 21 12 28 17 11 15 31  2 23 19  7 20 14 10 22  9 25  4 32  6\n",
      " 26 24 33  5 27 39  3  1 30 29 61 40 46 41 36 34 35 50 43 42 37 51 38 45\n",
      " 54 52 49 62 55 47 44 53 48 57 59 56 60 63 58 70 67 64 69 65 68 66 81 79\n",
      " 75 72 74]\n",
      "number_outpatient  : \n",
      "[ 0  2  1  5  7  9  3  8  4 12 11  6 20 15 10 13 14 16 21 35 17 29 36 18\n",
      " 19 27 22 24 42 39 34 26 33 25 23 28 37 38 40]\n",
      "number_emergency  : \n",
      "[ 0  1  4  2  3  9  7  5  6  8 22 25 10 13 42 16 11 28 15 14 18 12 21 20\n",
      " 19 46 76 37 64 63 54 24 29]\n",
      "number_inpatient  : \n",
      "[ 0  1  2  3  6  5  4  7  9  8 15 10 11 14 12 13 16 21 18 19]\n",
      "diag_1  : \n",
      "['276' '648' '8' '197' '414' '428' '398' '434' '250.7' '157' '518' '999'\n",
      " '410' '682' '402' '737' '572' 'V57' '189' '786' '427' '996' '277' '584'\n",
      " '462' '473' '411' '174' '486' '998' '511' '626' '295' '196' '250.6' '618'\n",
      " '182' '845' '423' '808' '250.4' '722' '784' '707' '440' '151' '715' '198'\n",
      " '564' '812' '997' '403' '38' '590' '556' '578' '250.32' '433' 'V58' '569'\n",
      " '185' '536' '255' '250.13' '599' '558' '574' '491' '560' '244' '250.03'\n",
      " '577' '730' '188' '824' '250.8' '332' '562' '291' '296' '510' '401' '263'\n",
      " '438' '70' '642' '625' '571' '738' '593' '250.42' '807' '456' '446' '575'\n",
      " '250.41' '250.02' '820' '515' '780' '250.22' '995' '235' '250.82' '721'\n",
      " '787' '724' '282' '250.83' '514' 'V55' '281' '250.33' '530' '466' '435'\n",
      " '250.12' 'V53' '789' '566' '822' '191' '557' '432' '733' '162' '455'\n",
      " '711' '482' '202' '493' '280' '553' '225' '154' '441' '250.81' '349'\n",
      " '962' '592' '507' '386' '156' '200' '728' '348' '426' '388' '607' '337'\n",
      " '82' '531' '596' '288' '656' '573' '492' '220' '516' '210' '922' '286'\n",
      " '885' '958' '661' '969' '227' '112' '404' '823' '532' '416' '346' '535'\n",
      " '453' '250' '595' '211' '303' '852' '218' '782' '540' '457' '285' '340'\n",
      " '54' '351' '601' '723' '555' '153' '443' '380' '424' '241' '358' '694'\n",
      " '331' '345' '681' '447' '290' '158' '579' '436' '335' '309' '654' '805'\n",
      " '799' '292' '183' '78' '851' '431' '458' '586' '311' '892' '305' '293'\n",
      " '415' '591' '794' '250.11' '79' '655' '429' '278' '658' '598' '729' '585'\n",
      " '444' '727' '214' '552' '284' '41' '644' '481' '821' '413' '437' '968'\n",
      " '756' '632' '359' '275' '512' '781' '420' '368' '522' '294' '825' '135'\n",
      " '304' '320' '250.31' '669' '868' '496' '826' '567' '3' '203' '680' '459'\n",
      " '53' '251' '565' '161' '495' '49' '250.1' '297' '663' '250.43' '576'\n",
      " '355' '850' '287' '250.2' '611' '840' '350' '726' '537' '620' '180' '366'\n",
      " '783' '11' '751' '250.3' '199' '464' '580' '836' '664' '283' '813' '966'\n",
      " '289' '708' '965' '184' '604' '480' '608' '333' '972' '212' '117' '788'\n",
      " '924' '959' '621' '238' '785' '714' '942' '250.23' '710' '47' '933' '508'\n",
      " '844' '7' '233' '42' '250.5' '397' '395' '201' '421' '478' '253' '250.92'\n",
      " '600' '494' '977' '716' '39' '659' '312' '614' '647' '652' '646' '274'\n",
      " '861' '425' '527' '451' '485' '217' '250.53' '442' '970' '193' '160'\n",
      " '322' '581' '475' '623' '374' '582' '568' '465' '801' '237' '376' '150'\n",
      " '461' '913' '617' '987' '641' '298' '550' '336' '362' '228' '513' '383'\n",
      " '746' '353' '911' '506' '873' '155' '860' '534' '802' '141' 'V45' '396'\n",
      " '310' '341' '242' '719' '736' '239' '533' '616' '519' '301' 'V66' '5'\n",
      " '989' '230' '385' '300' '853' '871' '570' '848' '9' '790' '934' '250.21'\n",
      " '236' '361' '594' '501' '810' '250.93' '643' '430' '528' '205' '791'\n",
      " '983' '992' '490' '172' '171' '622' '306' '863' '864' '474' '660' '759'\n",
      " '204' '356' '634' '967' '551' '695' '187' '732' '747' '323' '308' '370'\n",
      " '252' '152' '846' '365' '718' '48' '266' '720' '94' '344' '797' '170'\n",
      " '878' '904' 'V56' '882' '843' '709' '973' '454' '686' '939' '487' '229'\n",
      " '991' '226' '483' '357' '692' '796' '693' '935' '936' '800' '920' '261'\n",
      " '307' '262' '831' '145' '223' 'V71' '839' '685' 'V54' '35' '34' '179'\n",
      " '964' '136' '324' '389' '815' '334' '143' '526' '588' '250.01' '192'\n",
      " 'V67' '394' '917' '88' '219' '325' '792' '717' '994' '990' '793' '207'\n",
      " '637' '195' '373' '847' '827' '164' '31' '891' '814' 'V60' '703' '865'\n",
      " '352' '627' '378' '342' '886' '369' '745' '705' '816' '541' '986' '610'\n",
      " '633' '640' '753' '173' '835' '379' '445' '382' '945' '619' '881'\n",
      " '250.52' '866' '405' '916' '215' '893' '75' '671' '928' '906' '897' '725'\n",
      " '867' '115' '890' '734' '674' '521' '470' '834' '146' '696' '524' '980'\n",
      " '691' '384' '142' '879' '250.51' '246' '955' '250.9' '653' '149' '245'\n",
      " '735' '883' '854' '952' '838' '194' 'V43' '163' '216' '147' '27' '477'\n",
      " '318' '880' '921' '377' '471' '683' '272' '448' '175' '602' '250.91'\n",
      " '982' '706' '375' '417' '131' '463' '347' '870' '148' '354' 'V26' '862'\n",
      " '61' '817' '914' '360' '684' '314' 'V63' '36' '57' '240' '208' '915'\n",
      " '971' '795' '988' '452' '327' '731' '842' 'V25' '645' '803' '665' '110'\n",
      " '944' '923' '412' '363' '957' '976' '698' '299' '700' '273' '974' '97'\n",
      " '529' '66' '98' '605' '941' '52' '84' '271' '837' '657' '895' '338' '523'\n",
      " '806' '542' '114' '543' '372' 'E909' '583' 'V07' '422' '963' '615' '279'\n",
      " '500' '903' '919' '875' '381' '704' '23' '58' '649' '603' '832' '133'\n",
      " '975' '833' '391' '690' '10' 'V51']\n",
      "diag_2  : \n",
      "['250.01' '250' '250.43' '157' '411' '492' '427' '198' '403' '288' '998'\n",
      " '507' '174' '425' '456' '401' '715' '496' '428' '585' '250.02' '410'\n",
      " '999' '996' '135' '244' '41' '571' '276' '599' '424' '491' '553' '707'\n",
      " '997' '286' '440' '493' '242' '70' 'V45' '250.03' '357' '511' '196' '396'\n",
      " '197' '414' '250.52' '577' '535' '413' '285' '53' '780' '518' '150' '566'\n",
      " '250.6' '867' '486' 'V15' '8' '788' '340' '574' '581' '228' '530'\n",
      " '250.82' '786' '294' '567' '785' '512' '305' '729' '250.51' '280' '648'\n",
      " '560' '618' '444' '38' 'V10' '578' '277' '781' '250.42' '426' '584' '402'\n",
      " '153' '272' '733' '34' '881' '203' '250.41' '250.13' '293' '250.12' '787'\n",
      " '342' '573' '626' '303' '250.53' '458' '710' '415' 'V42' '284' '569'\n",
      " '759' '682' '112' '292' '435' '290' '250.93' '642' '398' '319' '711'\n",
      " 'E878' '446' '255' 'V44' '250.7' '784' '300' '562' '162' '287' '447'\n",
      " '789' '790' '591' '200' '154' '304' '117' '847' '852' '250.83' '250.11'\n",
      " '816' '575' '416' '412' '441' '515' '482' '382' '572' '283' '78' '250.81'\n",
      " '576' '536' '295' 'V12' '204' '466' '721' '434' '590' '271' '813' '368'\n",
      " '227' '783' '250.5' '258' '253' '309' '250.91' '519' '333' '459' '250.92'\n",
      " '250.4' '179' '420' '345' '433' '661' '537' '205' '722' '405' '437' '714'\n",
      " '211' '263' '202' '397' '250.23' 'E932' '301' '723' '614' '568' '861'\n",
      " 'V57' '724' '189' '297' '453' 'E888' '730' '278' '354' '201' '462' '451'\n",
      " '738' 'E939' '805' 'V43' '155' '910' '218' '358' '220' 'E937' '958' '794'\n",
      " '564' '250.22' '620' '621' '331' '617' '596' '378' '250.8' '625' '478'\n",
      " '731' '172' '404' '681' '558' '470' '279' '281' '531' '443' '799' '436'\n",
      " '337' '311' '719' 'E944' '423' 'E870' '465' 'E849' '782' '481' '480'\n",
      " 'V23' '199' '438' '348' '42' '583' 'E950' '473' '627' '726' '54' '490'\n",
      " '317' '332' '508' '600' '349' '79' '485' '922' '431' '296' 'E934' '753'\n",
      " 'E935' '386' '728' 'E915' '344' '716' '289' '191' '873' '850' '611' '377'\n",
      " '352' '616' 'V17' '136' '455' '933' 'E885' '860' '513' '607' '603' '484'\n",
      " '223' 'V72' '291' '151' 'V58' '550' '510' '891' '592' '791' '138' '598'\n",
      " '336' '362' '217' '825' '298' '821' 'E880' '343' '429' 'E879' '579' '225'\n",
      " '250.9' 'V49' '696' '233' '185' '658' '969' '275' '595' '250.1' '601'\n",
      " '808' 'E890' '920' '380' '570' 'E817' '359' '812' '274' 'V14' '324' '758'\n",
      " 'V66' '911' 'E931' 'E924' '593' '792' '727' 'V46' '394' '532' 'V64' '557'\n",
      " '864' '718' 'E942' '807' '604' '924' '820' '580' '273' '241' 'V65' '282'\n",
      " '824' 'V61' '646' '701' '736' '565' '383' '250.2' 'E947' '872' '905'\n",
      " 'E930' '921' '131' '448' '389' '421' '214' '705' '494' '623' '9' '299'\n",
      " '959' '365' '967' 'E858' '40' '691' '432' '909' '5' '814' '746' '250.31'\n",
      " '556' '680' '745' '351' '306' '110' '695' '552' '346' '918' '882' '947'\n",
      " '520' '188' '31' '356' '737' 'V08' '322' '182' '517' '974' 'E929' 'V53'\n",
      " '912' '252' '608' '516' '94' '702' '923' '594' '647' '934' '430' '487'\n",
      " '709' '796' '156' 'E812' '977' '915' '756' '840' '341' '693' '725' 'V62'\n",
      " '528' '683' '953' '457' '501' 'E900' 'V09' '522' '919' '461' '506' '193'\n",
      " '259' '483' 'E936' '717' '802' '335' 'V54' '452' '320' '945' '906' '239'\n",
      " '454' '826' '823' 'E941' '226' '795' '684' '844' '250.33' '308' '615'\n",
      " '588' '712' '663' '706' '833' '741' '713' '533' '372' 'E884' '586' '555'\n",
      " 'E933' '755' 'E928' '742' '869' '962' 'V11' '543' '208' '373' '870' '152'\n",
      " '810' '965' '907' '908' '995' '845' '474' '442' '751' '323' '472' '464'\n",
      " '686' '250.32' '540' '251' '811' '652' '659' '851' '422' '815' '307'\n",
      " '325' '463' '992' '692' '521' '369' '917' 'E965' '524' 'E813' '173' '238'\n",
      " '137' '312' '837' '355' '622' '475' '500' '754' '261' '868' '968' '381'\n",
      " '11' '250.21' '694' '610' '734' 'E814' '310' '246' '892' '846' '634' '75'\n",
      " 'E927' 'E905' '314' '183' '379' 'E917' '163' '514' 'E868' '495' '747'\n",
      " '989' 'E854' '240' '832' '602' '644' 'V16' '801' 'V18' '35' 'V70' '376'\n",
      " '266' 'E918' '619' '477' '656' '46' '883' '171' 'V13' '698' '842' 'E850'\n",
      " '800' '269' '664' 'E887' '952' '164' 'E881' '527' '366' '836' '27' 'V63'\n",
      " '865' '793' '232' '245' '990' '52' '831' '327' '542' '972' '862' 'E829'\n",
      " 'E919' '944' 'E916' '963' '316' '980' '645' '347' 'V85' '374' 'V02' '748'\n",
      " '256' '186' '866' '975' '96' '395' '262' 'E819' '654' '994' '318' 'E826'\n",
      " '685' '879' '674' '641' '822' '145' '797' '913' '353' 'E938' 'E816' '948'\n",
      " '987' '99' '192' '250.3' 'E906' '534' '115' 'E818' 'E980' '360' '338'\n",
      " '529' '871' '750' '212' '806' '302' '955' '141' '88' 'V25' '916' '215'\n",
      " '350' 'V50' 'E853' 'E968' 'E882' '140' '703' '991' '893' 'E821' '235'\n",
      " 'V69' '670' '195' 'V55' '388' '268' '894' '114' '260' '7' '880' '853'\n",
      " 'V86' '180' 'E945' '523' '863' '649' '270' '665' '460' '942' '364' '66'\n",
      " 'E883' '123' '884' 'V60' '843' '927']\n",
      "diag_3  : \n",
      "['255' 'V27' '403' '250' 'V45' '38' '486' '996' '197' '250.6' '427' '627'\n",
      " '414' '416' '714' '428' '582' 'V43' '250.01' '263' '250.42' '276' '482'\n",
      " '401' '250.41' '585' '781' '278' '998' '568' '682' '618' '250.02' '305'\n",
      " '707' '496' '715' '424' '518' '553' '794' '411' 'V42' '531' '511' '490'\n",
      " '562' '250.8' '599' '250.7' '250.52' '491' '581' '420' '8' '724' '730'\n",
      " '789' '131' '250.82' '999' '41' '493' '250.03' '753' '786' '529' 'E888'\n",
      " '425' '595' '303' '560' '711' '492' '332' '296' '438' '362' '250.4' '654'\n",
      " '244' 'V70' '737' '625' '681' '250.51' '404' 'V10' '810' '280' '440'\n",
      " '785' '588' '569' '272' '997' '250.43' '918' '584' '54' '788' '426' '722'\n",
      " '250.92' '461' '535' '787' '891' '284' '458' '648' '780' '182' '285'\n",
      " '593' '413' '664' '564' '201' '356' 'V15' '292' '196' '782' '784' '473'\n",
      " '455' 'E932' '357' '294' '250.23' '459' 'E878' '437' '733' '507' '525'\n",
      " '250.53' '397' '572' '805' '453' '331' '736' '402' '591' '576' '465'\n",
      " '533' '703' '349' '315' '658' '608' '578' '716' '382' '300' '282' '571'\n",
      " '536' '596' '287' '644' 'V11' '558' 'E885' '162' '198' '218' '412' '396'\n",
      " 'V14' '570' '433' 'E934' '882' '288' '577' '443' '729' '836' '295' '799'\n",
      " '281' '304' '153' '410' '616' '250.83' '601' '291' '75' '512' '660'\n",
      " '250.5' '598' '337' '574' '653' 'V58' '311' '386' '602' '790' '112' '873'\n",
      " '620' '436' '70' '155' '138' '663' '530' '710' '42' '342' '250.91' 'E884'\n",
      " '515' '307' '704' '728' '731' '583' '238' '441' '293' '573' '532' '290'\n",
      " '319' '250.13' '250.12' '519' '346' '380' '135' '642' '698' '924' '905'\n",
      " 'E933' '555' '309' 'E879' '286' '565' '752' '580' '446' '444' '344' '252'\n",
      " '35' '813' '394' '301' '575' '258' 'V17' '802' '435' '746' 'V12' '709'\n",
      " '881' 'E935' '139' '250.81' '718' '365' '202' '334' '185' '398' 'V44'\n",
      " '517' 'E849' '614' '466' '626' '250.9' '368' '605' '883' '289' '478'\n",
      " '617' '429' '442' 'V25' '866' '610' '557' '959' 'E942' '94' '920' '345'\n",
      " '313' '379' '79' '516' '586' '821' '600' '242' '373' '592' 'V64' '487'\n",
      " '253' '706' 'E947' '117' '340' 'E950' '656' 'E949' '590' 'V09' '934'\n",
      " '694' '203' '250.93' '995' '726' '923' '958' '275' 'E929' '211' 'V18'\n",
      " '199' '665' '279' '522' '791' '890' '456' 'E938' 'E816' '122' '721' 'V65'\n",
      " '136' '480' '423' 'E920' '793' '647' '537' '351' '415' '53' '845' '336'\n",
      " '274' '719' '945' '434' '494' '227' '157' '208' '174' 'V57' '812' '734'\n",
      " 'V23' '447' '692' '228' '348' 'V16' '756' '405' 'E928' '823' '552' '528'\n",
      " '389' '240' '454' '792' '366' 'E939' '907' '270' '310' '266' '387' 'E931'\n",
      " '783' '245' '607' '355' 'E930' '705' '372' '369' '611' '283' 'V46' '110'\n",
      " '867' 'E956' '251' '250.2' '820' '712' '695' '567' '343' '723' 'V08'\n",
      " '273' '623' '807' '451' '495' '701' '34' 'V53' '314' '472' 'E945' '11'\n",
      " '189' '534' '354' '333' 'V54' '277' '659' '708' '452' '655' '816' '670'\n",
      " '621' '246' '953' '865' 'E817' '646' '151' '378' '78' '298' '840' '641'\n",
      " '521' '745' '619' '912' '506' 'E904' '259' 'E870' '594' 'E980' '383'\n",
      " 'V66' '204' '696' '566' '727' '47' 'E943' '358' '191' '965' '921' '432'\n",
      " '27' '150' 'E861' '758' '477' '524' '751' '652' '556' '825' '919' '732'\n",
      " '908' '951' '962' '685' 'E850' 'E944' '527' '341' '693' '250.1' 'V49'\n",
      " '860' '323' 'V55' '579' '508' '969' '205' '462' 'E880' '680' '697' '826'\n",
      " '200' '457' '717' '738' '742' '735' '235' '308' '725' '241' '824' '464'\n",
      " '260' '917' '239' '661' '892' '261' 'E883' '943' '744' '188' 'E936' '796'\n",
      " '318' '967' '350' '854' 'E905' '9' '741' 'E941' '170' '643' '317' '759'\n",
      " '909' 'V22' '831' '713' '180' '801' '360' '359' '501' '335' '250.11'\n",
      " '306' '811' '690' 'V02' '271' '214' '250.22' '847' '543' 'V63' '906'\n",
      " '842' '686' '445' '808' '861' 'E852' '220' 'E887' 'E858' '915' '970'\n",
      " '256' '747' '395' '243' '815' '481' '5' 'E927' '297' '299' '851' '864'\n",
      " '922' '384' 'E876' '225' '158' 'E937' '871' '88' '966' 'E917' 'E812'\n",
      " 'V62' 'E924' '604' '233' 'E916' '377' '797' 'V72' '172' '7' '421' '852'\n",
      " 'E819' '972' '916' '956' '3' 'E965' '173' '193' '154' '347' '862' '250.3'\n",
      " '987' '470' '262' 'E855' '161' '115' '179' '910' '312' '17' '460' '265'\n",
      " '66' '163' 'V60' '870' 'E906' '514' '944' '844' '417' '152' '183' '991'\n",
      " '216' '385' '164' '935' '510' '814' '485' '850' '250.21' 'E919' '872'\n",
      " '195' '431' '597' '933' '171' '884' '156' '868' '483' 'E815' '542' 'V61'\n",
      " '853' '374' 'E881' 'E882' 'E822' '192' '754' '327' '523' '500' 'V85'\n",
      " '992' '657' '684' '603' 'E826' '550' '913' '376' '755' '361' '186' '720'\n",
      " '250.31' '674' '911' 'E813' '226' '365.44' 'E818' '146' '955' 'E894'\n",
      " '475' 'V13' '880' '930' 'E915' '381' '132' '353' '795' '893' 'V01' 'E853'\n",
      " '863' '540' 'E828' '430' 'E865' '148' 'E946' '822' '879' '848' 'V86'\n",
      " 'V03' '338' '989' '388' 'E966' '111' 'E922' '123' '757' 'E901' '141'\n",
      " '268' 'E892' '649' '702' '948' '223' '484' 'E886' '838' '928' '236' '624'\n",
      " '837' 'E987' 'V07' '841' '800' '622' 'E912' '463' 'V06' 'E864' '217'\n",
      " '877' '391' 'E825' '952' '669' '875' 'E900' '215' '538' '980' '834' '448'\n",
      " '175' '49' '876' '230' '57' 'E854' '14' '750' '370' '671' '971']\n",
      "number_diagnoses  : \n",
      "[ 9  6  7  5  8  3  4 16 12 13 15 10 11 14]\n",
      "max_glu_serum  : \n",
      "['None' '>300' 'Norm' '>200']\n",
      "A1Cresult  : \n",
      "['None' '>7' '>8' 'Norm']\n",
      "metformin  : \n",
      "[0 1]\n",
      "repaglinide  : \n",
      "[0 1]\n",
      "nateglinide  : \n",
      "[0 1]\n",
      "chlorpropamide  : \n",
      "[0 1]\n",
      "glimepiride  : \n",
      "[0 1]\n",
      "acetohexamide  : \n",
      "[0 1]\n",
      "glipizide  : \n",
      "[0 1]\n",
      "glyburide  : \n",
      "[0 1]\n",
      "tolbutamide  : \n",
      "[0 1]\n",
      "pioglitazone  : \n",
      "[0 1]\n",
      "rosiglitazone  : \n",
      "[0 1]\n",
      "acarbose  : \n",
      "[0 1]\n",
      "miglitol  : \n",
      "[0 1]\n",
      "troglitazone  : \n",
      "[0 1]\n",
      "tolazamide  : \n",
      "[0 1]\n",
      "insulin  : \n",
      "[1 0]\n",
      "glyburide-metformin  : \n",
      "[0 1]\n",
      "glipizide-metformin  : \n",
      "[0 1]\n",
      "glimepiride-pioglitazone  : \n",
      "[0 1]\n",
      "metformin-rosiglitazone  : \n",
      "[0 1]\n",
      "metformin-pioglitazone  : \n",
      "[0 1]\n",
      "change  : \n",
      "[1 0]\n",
      "diabetesMed  : \n",
      "[1 0]\n",
      "readmitted  : \n",
      "['>30' 'NO' '<30']\n"
     ]
    }
   ],
   "source": [
    "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', \n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', \n",
    "        'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', \n",
    "        'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "\n",
    "for col in keys:\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)\n",
    "    \n",
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "\n",
    "df['age'] = df['age'].replace('[0-10)', 5)\n",
    "df['age'] = df['age'].replace('[10-20)', 15)\n",
    "df['age'] = df['age'].replace('[20-30)', 25)\n",
    "df['age'] = df['age'].replace('[30-40)', 35)\n",
    "df['age'] = df['age'].replace('[40-50)', 45)\n",
    "df['age'] = df['age'].replace('[50-60)', 55)\n",
    "df['age'] = df['age'].replace('[60-70)', 65)\n",
    "df['age'] = df['age'].replace('[70-80)', 75)\n",
    "df['age'] = df['age'].replace('[80-90)', 85)\n",
    "df['age'] = df['age'].replace('[90-100)', 95)\n",
    "\n",
    "df['race'] = df['race'].replace('Caucasian', 0)\n",
    "df['race'] = df['race'].replace('AfricanAmerican', 1)\n",
    "df['race'] = df['race'].replace('Hispanic', 2)\n",
    "df['race'] = df['race'].replace('Asian', 3)\n",
    "df['race'] = df['race'].replace('Other', 4)\n",
    "\n",
    "df = df.replace('?', -1)\n",
    "#df.head()\n",
    "\n",
    "for col in df:\n",
    "    print(col, \" : \")\n",
    "    print(df[col].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[(df.diag_1.str.contains('V')),'diag_1']=0\n",
    "# df.loc[(df.diag_1.str.contains('E')),'diag_1']=0\n",
    "\n",
    "# df.loc[(df.diag_2.str.contains('V')),'diag_2']=0\n",
    "# df.loc[(df.diag_2.str.contains('E')),'diag_2']=0\n",
    "\n",
    "# df.loc[(df.diag_3.str.contains('V')),'diag_3']=0\n",
    "# df.loc[(df.diag_3.str.contains('E')),'diag_3']=0\n",
    "\n",
    "# for i in df['diag_1']:\n",
    "#     b = 'V' in str(i)\n",
    "#     c = 'E' in str(i)\n",
    "#     if b or c:\n",
    "#         print(str(i))\n",
    "        \n",
    "        \n",
    "# for i in df['diag_2']:\n",
    "#     b = 'V' in str(i)\n",
    "#     c = 'E' in str(i)\n",
    "#     if b or c:\n",
    "#         print(str(i))\n",
    "        \n",
    "        \n",
    "# for i in df['diag_3']:\n",
    "#     b = 'V' in str(i)\n",
    "#     c = 'E' in str(i)\n",
    "#     if b or c:\n",
    "#         print(str(i))\n",
    "\n",
    "diags = ['diag_1','diag_2','diag_3']\n",
    "    \n",
    "def detection(value):\n",
    "    if value[0]== \"V\" or value[0] == 'E':\n",
    "        value = '0'\n",
    "        return value # from new york united healthcare\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "for f in diags:\n",
    "    for i in df[f].index:\n",
    "        df[f].at[i] = detection(df[f].at[i])\n",
    "        \n",
    "for i in df['diag_1']:\n",
    "    b = 'V' in str(i)\n",
    "    c = 'E' in str(i)\n",
    "    if b or c:\n",
    "        print(str(i))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race                         int64\n",
       "gender                       int64\n",
       "age                          int64\n",
       "admission_type_id            int64\n",
       "discharge_disposition_id     int64\n",
       "admission_source_id          int64\n",
       "time_in_hospital             int64\n",
       "num_lab_procedures           int64\n",
       "num_procedures               int64\n",
       "num_medications              int64\n",
       "diag_1                      object\n",
       "diag_2                      object\n",
       "diag_3                      object\n",
       "number_diagnoses             int64\n",
       "max_glu_serum               object\n",
       "A1Cresult                   object\n",
       "metformin                    int64\n",
       "repaglinide                  int64\n",
       "nateglinide                  int64\n",
       "chlorpropamide               int64\n",
       "glimepiride                  int64\n",
       "acetohexamide                int64\n",
       "glipizide                    int64\n",
       "glyburide                    int64\n",
       "tolbutamide                  int64\n",
       "pioglitazone                 int64\n",
       "rosiglitazone                int64\n",
       "acarbose                     int64\n",
       "miglitol                     int64\n",
       "troglitazone                 int64\n",
       "tolazamide                   int64\n",
       "insulin                      int64\n",
       "glyburide-metformin          int64\n",
       "glipizide-metformin          int64\n",
       "glimepiride-pioglitazone     int64\n",
       "metformin-rosiglitazone      int64\n",
       "metformin-pioglitazone       int64\n",
       "change                       int64\n",
       "diabetesMed                  int64\n",
       "readmitted                  object\n",
       "service_utilization          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
    "#print(\"geelo \", df.columns)\n",
    "df.drop(['number_outpatient', 'number_emergency', 'number_inpatient'], axis=1, inplace=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "#df_age = pd.get_dummies(df['age'])\n",
    "#df_race = pd.get_dummies(df['race'])\n",
    "#df_gender = pd.get_dummies(df['gender'])\n",
    "#df_change = pd.get_dummies(df['change'])\n",
    "#df_diabetesMed = pd.get_dummies(df['diabetesMed'])\n",
    "\n",
    "df_max_glu_serum = pd.get_dummies(df['max_glu_serum'])\n",
    "df_A1Cresult = pd.get_dummies(df['A1Cresult'])\n",
    "df_insulin = pd.get_dummies(df['insulin'])\n",
    "df_discharge_disposition_id = pd.get_dummies(df['discharge_disposition_id'])\n",
    "df_admission_source_id = pd.get_dummies(df['admission_source_id'])\n",
    "df_admission_type_id = pd.get_dummies(df['admission_type_id'])\n",
    "\n",
    "#print(df_max_glu_serum)\n",
    "#df = pd.concat([df,df_max_glu_serum])\n",
    "#df.drop(['max_glu_serum'], axis=1, inplace=True)             \n",
    "df = pd.concat([df,df_max_glu_serum, df_A1Cresult, \n",
    "                df_insulin, df_discharge_disposition_id, \n",
    "                df_admission_source_id, df_admission_type_id], axis=1)\n",
    "df.drop([ 'max_glu_serum', 'A1Cresult', 'insulin','discharge_disposition_id', 'admission_source_id', \n",
    "                  'admission_type_id'], axis=1, inplace=True)\n",
    "#before\n",
    "\n",
    "#print(df.shape)\n",
    "# df = df['readmitted' == 1 or 'readmitted' == 0]\n",
    "#df.readmitted = np.where(df.readmitted=2, 0, df.readmitted)\n",
    "#after\n",
    "# df.groupby('readmitted').size().plot(kind='bar')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title(\"AFTER CHANGE\")\n",
    "# plt.show()\n",
    "# #print(df.iloc[0])\n",
    "# #df.head()\n",
    "# df.head()\n",
    "\n",
    "dfcopy = df.copy(deep=True)\n",
    "df['readmitted'] = df['readmitted'].replace('>30', 1)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1) #should we code it into 1 and 2?\n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)\n",
    "#f.readmitted.value_counts()\n",
    "\n",
    "df.groupby('readmitted').size().plot(kind='bar')\n",
    "plt.ylabel('DF READMITTED Count - 2 labels')\n",
    "plt.show()\n",
    "print(df['readmitted'].unique())\n",
    "\n",
    "dfcopy['readmitted'] = dfcopy['readmitted'].replace('>30', 2)\n",
    "dfcopy['readmitted'] = dfcopy['readmitted'].replace('<30', 1) \n",
    "dfcopy['readmitted'] = dfcopy['readmitted'].replace('NO', 0)\n",
    "#f.readmitted.value_counts()\n",
    "\n",
    "dfcopy.groupby('readmitted').size().plot(kind='bar')\n",
    "plt.ylabel('DF READMITTED Copy Count - 3 labels')\n",
    "plt.show()\n",
    "print(dfcopy['readmitted'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_col_names = df.columns\n",
    "#print(df.columns)\n",
    "#x = df[feature_col_names]\n",
    "#x = x.drop('readmitted', axis=1)\n",
    "x = df.loc[:, df.columns != 'readmitted']\n",
    "y = df['readmitted']\n",
    "#print(x.columns, y)\n",
    "#print(y.unique())\n",
    "#print(x, y)\n",
    "#print(x.iloc[0])\n",
    "#print(y.iloc[0])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
    "\n",
    "x_copy = dfcopy.loc[:, dfcopy.columns != 'readmitted']\n",
    "y_copy = dfcopy['readmitted']\n",
    "\n",
    "X_train_copy, X_test_copy, Y_train_copy, Y_test_copy = train_test_split(x_copy, y_copy, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 87351, 1: 11250})\n",
      "New dataset shape Counter({0: 87351, 1: 87351})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "# TWO CLASS LABELS _ BINARY\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_sample(x.values, y)\n",
    "print('New dataset shape {}'.format(Counter(train_output_new)))\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(x.columns))\n",
    "X_train_SMOTE, X_test_SMOTE, Y_train_SMOTE, Y_test_SMOTE = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "# print(X_dev)\n",
    "# print(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 52178, 2: 35173, 1: 11250})\n",
      "New dataset shape Counter({2: 52178, 0: 52178, 1: 52178})\n"
     ]
    }
   ],
   "source": [
    "# THREE CLASS LABELS\n",
    "print('Original dataset shape {}'.format(Counter(y_copy)))\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_sample(x_copy.values, y_copy)\n",
    "print('New dataset shape {}'.format(Counter(train_output_new)))\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(x_copy.columns))\n",
    "X_train_copy_SMOTE, X_test_copy_SMOTE, Y_train_copy_SMOTE, Y_test_copy_SMOTE = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x.iloc[[2, 3, 4]].values)\n",
    "#print(x.values[[2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going....\n",
      "accuracy: 92.00%\n",
      "Going....\n",
      "accuracy: 92.00%\n",
      "Going....\n",
      "accuracy: 92.00%\n",
      "Going....\n",
      "accuracy: 88.00%\n",
      "Going....\n",
      "accuracy: 92.00%\n",
      "Going....\n",
      "accuracy: 88.00%\n",
      "Going....\n",
      "accuracy: 84.00%\n",
      "Going....\n",
      "accuracy: 88.00%\n",
      "Going....\n",
      "accuracy: 88.00%\n",
      "Going....\n",
      "accuracy: 72.00%\n",
      "87.60% (+/- 5.78%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(x[:250], y[:250]):\n",
    "    print(\"Going....\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=94, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Fit the model\n",
    "    model.fit(x[:250].values[train], y[:250].values[train], epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "    scores = model.evaluate(x[:250].values[test], y[:250].values[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) \n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going....\n",
      "accuracy: 8.00%\n",
      "Going....\n",
      "accuracy: 8.00%\n",
      "Going....\n",
      "accuracy: 12.00%\n",
      "Going....\n",
      "accuracy: 12.00%\n",
      "Going....\n",
      "accuracy: 12.00%\n",
      "Going....\n",
      "accuracy: 16.00%\n",
      "Going....\n",
      "accuracy: 12.00%\n",
      "Going....\n",
      "accuracy: 12.00%\n",
      "Going....\n",
      "accuracy: 12.00%\n",
      "Going....\n",
      "accuracy: 16.00%\n",
      "12.00% (+/- 2.53%)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(x_copy[:250], y_copy[:250]):\n",
    "    print(\"Going....\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=94, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Fit the model\n",
    "    model.fit(x_copy[:250].values[train], y_copy[:250].values[train], epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "    scores = model.evaluate(x_copy[:250].values[test], y_copy[:250].values[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) \n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(model):\n",
    "    x_scaled = preprocessing.scale(x)\n",
    "    \n",
    "    results = cross_val_score(model, x_scaled, y, cv=10, scoring='accuracy')\n",
    "    print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "    \n",
    "    results = cross_val_score(model, x_scaled, y, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC-AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "    \n",
    "    results = cross_val_score(model, x_scaled , y, cv=10, scoring='neg_log_loss') \n",
    "    print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "    # for some reason this piece of code not working with SVM\n",
    "    \n",
    "def printStatsSVM(model):\n",
    "    x_scaled = preprocessing.scale(x)\n",
    "    \n",
    "    results = cross_val_score(model, x_scaled, y, cv=10, scoring='accuracy')\n",
    "    print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "    \n",
    "    results = cross_val_score(model, x_scaled, y, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC-AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "    \n",
    "    #results = cross_val_score(model, x_scaled[:50] , y[:50], cv=3, scoring='neg_log_loss') \n",
    "    #print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "    # for some reason this piece of code not working with SVM\n",
    "    \n",
    "def printROC(Y_test, preds, title):\n",
    "    from sklearn.metrics import roc_auc_score, roc_curve\n",
    "    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(Y_test, preds)\n",
    "    plt.subplots(1, figsize=(10,10))\n",
    "    plt.title(title)\n",
    "    plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "    plt.plot([0, 1], ls=\"--\")\n",
    "    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "    print('roc_auc_score for DecisionTree: ', roc_auc_score(Y_test, preds))\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(Y_test, preds)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE-BINARY\n",
      "Accuracy is 0.82\n",
      "SMOTE-BINARY\n",
      "Accuracy is 0.90\n",
      "WITHOUT SMOTE - TRIPLE\n",
      "Accuracy is 0.48\n",
      "SMOTE - TRIPLE\n",
      "Accuracy is 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "# cross validation - dont rlly need to use sklearn just to compare\n",
    "#run minmax scaler every time in loop for cross valscore\n",
    "print(\"WITHOUT SMOTE-BINARY\")\n",
    "clf = tree.DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_test, preds)))\n",
    "#cm = confusion_matrix(Y_test, preds)\n",
    "#print(cm)\n",
    "\n",
    "print(\"SMOTE-BINARY\")\n",
    "clf = tree.DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "clf.fit(X_train_SMOTE, Y_train_SMOTE)\n",
    "preds = clf.predict(X_test_SMOTE)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_test_SMOTE, preds)))\n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "#print(cm)\n",
    "#print(\"Cross Validation score: {:.2%}\".format(np.mean(cross_val_score(clf,x,y, cv=10))))\n",
    "\n",
    "print(\"WITHOUT SMOTE - TRIPLE\")\n",
    "clf = tree.DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "clf.fit(X_train_copy, Y_train_copy)\n",
    "preds = clf.predict(X_test_copy)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_test_copy, preds)))\n",
    "\n",
    "print(\"SMOTE - TRIPLE\")\n",
    "clf = tree.DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "clf.fit(X_train_copy_SMOTE, Y_train_copy_SMOTE)\n",
    "preds = clf.predict(X_test_copy_SMOTE)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_test_copy_SMOTE, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printStats(clf)\n",
    "#printROC(Y_dev, preds, 'ROC Curve - Decison Tree')\n",
    "#cm = confusion_matrix(Y_test, preds)\n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE- BINARY\n",
      "ACCURACY  0.882206784645809\n",
      "SMOTE - BINARY\n",
      "ACCURACY  0.6206176125468648\n",
      "WITHOUT SMOTE - TRIPLE\n",
      "ACCURACY  0.5632067339384412\n",
      "SMOTE - TRIPLE\n",
      "ACCURACY  0.46021656498546654\n"
     ]
    }
   ],
   "source": [
    "#print(Xt.shape) # adding to avoid warning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"WITHOUT SMOTE- BINARY\")\n",
    "X_train_scaled = preprocessing.scale(X_train) #scaling to avoid convergence warning\n",
    "scaler = preprocessing.StandardScaler().fit(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "preds = model.predict(X_test_scaled)\n",
    "#cm = confusion_matrix(Y_test, preds)\n",
    "#print(cm)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test, preds))\n",
    "\n",
    "print(\"SMOTE - BINARY\")\n",
    "\n",
    "X_train_scaledSM = preprocessing.scale(X_train_SMOTE) #scaling to avoid convergence warning\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_SMOTE) \n",
    "X_test_scaledSM = scaler.transform(X_test_SMOTE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaledSM, Y_train_SMOTE)\n",
    "preds = model.predict(X_test_scaledSM)\n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "#print(cm)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_SMOTE, preds))\n",
    "\n",
    "print(\"WITHOUT SMOTE - TRIPLE\")\n",
    "X_train_scaled_copy = preprocessing.scale(X_train_copy) #scaling to avoid convergence warning\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_copy) \n",
    "X_test_scaled_copy = scaler.transform(X_test_copy)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled_copy, Y_train_copy)\n",
    "preds = model.predict(X_test_scaled_copy)\n",
    "#cm = confusion_matrix(Y_test, preds)\n",
    "#print(cm)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy, preds))\n",
    "\n",
    "\n",
    "print(\"SMOTE - TRIPLE\")\n",
    "\n",
    "X_train_scaledSM_copy = preprocessing.scale(X_train_copy_SMOTE) #scaling to avoid convergence warning\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_copy_SMOTE) \n",
    "X_test_scaledSM_copy = scaler.transform(X_test_copy_SMOTE)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaledSM_copy, Y_train_copy_SMOTE)\n",
    "preds = model.predict(X_test_scaledSM_copy)\n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "#print(cm)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy_SMOTE, preds))\n",
    "\n",
    "# from sklearn.model_selection import cross_validate, cross_val_score\n",
    "# num_folds = 10\n",
    "# seed = 1\n",
    "# num_instances = len(X_train)\n",
    "# kfold = cross_validate.Kfold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "# results = cross_val_score(model, x, y.ravel(), cv=kfold)\n",
    "\n",
    "#print(\"Cross Validation score: {:.2%}\".format(np.mean(cross_val_score(model, x, y, cv=10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printStats(model)\n",
    "#printROC(Y_dev, preds, 'ROC Curve - Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE - BINARY\n",
      "ACCURACY  0.26692358399675475\n",
      "SMOTE - BINARY\n",
      "ACCURACY  0.5500987378724135\n",
      "WITHOUT SMOTE - TRIPLE\n",
      "ACCURACY  0.3776177678616703\n",
      "SMOTE-TRIPLE\n",
      "ACCURACY  0.40879036637173793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "print(\"WITHOUT SMOTE - BINARY\")\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, Y_train) \n",
    "preds = nb.predict(X_test) \n",
    "#cm = confusion_matrix(Y_test, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test, preds))\n",
    "#print(cm)\n",
    "\n",
    "print(\"SMOTE - BINARY\")\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_SMOTE, Y_train_SMOTE) \n",
    "preds = nb.predict(X_test_SMOTE) \n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_SMOTE, preds))\n",
    "#print(cm)\n",
    "\n",
    "\n",
    "print(\"WITHOUT SMOTE - TRIPLE\")\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_copy, Y_train_copy) \n",
    "preds = nb.predict(X_test_copy) \n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy, preds))\n",
    "#print(cm)\n",
    "\n",
    "\n",
    "print(\"SMOTE-TRIPLE\")\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_copy_SMOTE, Y_train_copy_SMOTE) \n",
    "preds = nb.predict(X_test_copy_SMOTE) \n",
    "#cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy_SMOTE, preds))\n",
    "#print(cm)\n",
    "#not working well accuracy is 13%\n",
    "#naive bayes is a \"binary\" classifier it gets a better accuracy when there is only 0 and 1\n",
    "#print(\"Cross Validation score: {:.2%}\".format(np.mean(cross_val_score(nb, x, y, cv=10))))\n",
    "\n",
    "#printStats(nb)\n",
    "#printROC(Y_dev, preds, 'ROC Curve - Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE - BINARY\n",
      "Accuracy Score:   0.8806855636123929\n",
      "SMOTE - BINARY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   0.8386422827051315\n",
      "WITHOUT SMOTE - TRIPLE\n",
      "Accuracy Score:   0.5025100147051367\n",
      "SMOTE - TRIPLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   0.5561056632701952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "print(\"WITHOUT SMOTE - BINARY\")\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Accuracy Score:  \", accuracy_score(Y_test, preds ))\n",
    "\n",
    "\n",
    "print(\"SMOTE - BINARY\")\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train_SMOTE, Y_train_SMOTE)\n",
    "preds = clf.predict(X_test_SMOTE)\n",
    "print(\"Accuracy Score:  \", accuracy_score(Y_test_SMOTE, preds ))\n",
    "\n",
    "print(\"WITHOUT SMOTE - TRIPLE\")\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train_copy, Y_train_copy)\n",
    "preds = clf.predict(X_test_copy)\n",
    "print(\"Accuracy Score:  \", accuracy_score(Y_test_copy, preds ))\n",
    "\n",
    "\n",
    "print(\"SMOTE - TRIPLE\")\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train_copy_SMOTE, Y_train_copy_SMOTE)\n",
    "preds = clf.predict(X_test_copy_SMOTE)\n",
    "print(\"Accuracy Score:  \", accuracy_score(Y_test_copy_SMOTE, preds ))\n",
    "\n",
    "#printStats(model)\n",
    "#printROC(Y_dev, preds, 'ROC Curve - Neural Networks 1 - Cecilia code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE - BINARY\n",
      "ACCURACY  0.8832716393692004\n",
      "SMOTE - BINARY\n",
      "ACCURACY  0.9365215649237286\n",
      "WITHOUT SMOTE - TRIPLE\n",
      "ACCURACY  0.5689873738654226\n",
      "SMOTE - TRIPLE\n",
      "ACCURACY  0.6474590347206695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"WITHOUT SMOTE - BINARY\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators = 150)\n",
    "clf.fit(X_train, Y_train)\n",
    "preds = clf.predict(X_test)\n",
    "#cm = cm = confusion_matrix(Y_test, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test, preds))\n",
    "#print(cm)\n",
    "\n",
    "print(\"SMOTE - BINARY\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators = 150)\n",
    "clf.fit(X_train_SMOTE, Y_train_SMOTE)\n",
    "preds = clf.predict(X_test_SMOTE)\n",
    "#cm = cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_SMOTE, preds))\n",
    "#print(cm)\n",
    "\n",
    "print(\"WITHOUT SMOTE - TRIPLE\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators = 150)\n",
    "clf.fit(X_train_copy, Y_train_copy)\n",
    "preds = clf.predict(X_test_copy)\n",
    "#cm = cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy, preds))\n",
    "#print(cm)\n",
    "\n",
    "print(\"SMOTE - TRIPLE\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators = 150)\n",
    "clf.fit(X_train_copy_SMOTE, Y_train_copy_SMOTE)\n",
    "preds = clf.predict(X_test_copy_SMOTE)\n",
    "#cm = cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy_SMOTE, preds))\n",
    "#print(cm)\n",
    "#printStats(model)\n",
    "#printROC(Y_dev, preds, 'ROC Curve - Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"WITHOUT SMOTE\")\n",
    "# nn = ml.nnet.nnetClassify() \n",
    "# nn.init_weights([Xt.shape[1]] + [0]*1 + [3], 'random', Xt, Yt) # 0 hidden layers, 3 output, \n",
    "# nn.train(X_train, Y_train, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "# preds = nn.predict(X_test)\n",
    "# cm = cm = confusion_matrix(Y_test, preds)\n",
    "# print(\"ACCURACY \" , accuracy_score(Y_test, preds))\n",
    "# print(cm)\n",
    "\n",
    "# print(\"SMOTE\")\n",
    "# nn = ml.nnet.nnetClassify()\n",
    "# nn.init_weights([Xt.shape[1]] + [0]*1 + [3], 'random', Xt, Yt) # 0 hidden layers, 3 output, \n",
    "# nn.train(X_train, Y_train, stopTol=1e-8, stepsize=.25, stopIter=300)\n",
    "# preds = nn.predict(X_dev)\n",
    "# cm = cm = confusion_matrix(Y_dev, preds)\n",
    "# print(\"ACCURACY \" , accuracy_score(Y_dev, preds))\n",
    "# print(cm)\n",
    "\n",
    "\n",
    "\n",
    "# #printStats(model)\n",
    "# #printROC(Y_dev, preds, 'ROC Curve - Neural Networks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE - BINARY\n",
      "ACCURACY  0.864\n",
      "SMOTE - BINARY\n",
      "ACCURACY  0.536\n",
      "WITHOUT SMOTE - TRIPLE\n",
      "ACCURACY  0.536\n",
      "SMOTE - TRIPLE\n",
      "ACCURACY  0.332\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#testing on small amounts for SVM\n",
    "print(\"WITHOUT SMOTE - BINARY\")\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train[:250], Y_train[:250])\n",
    "preds = clf.predict(X_test[:250])\n",
    "#cm = cm = confusion_matrix(Y_test, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test[:250], preds))\n",
    "#print(cm)\n",
    "\n",
    "print(\"SMOTE - BINARY\")\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_SMOTE[:250], Y_train_SMOTE[:250])\n",
    "preds = clf.predict(X_test_SMOTE[:250])\n",
    "#cm = cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_SMOTE[:250], preds))\n",
    "#print(cm)\n",
    "\n",
    "print(\"WITHOUT SMOTE - TRIPLE\")\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_copy[:250], Y_train_copy[:250])\n",
    "preds = clf.predict(X_test_copy[:250])\n",
    "#cm = cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy[:250], preds))\n",
    "\n",
    "print(\"SMOTE - TRIPLE\")\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_copy_SMOTE[:250], Y_train_copy_SMOTE[:250])\n",
    "preds = clf.predict(X_test_copy_SMOTE[:250])\n",
    "#cm = cm = confusion_matrix(Y_test_SMOTE, preds)\n",
    "print(\"ACCURACY \" , accuracy_score(Y_test_copy_SMOTE[:250], preds))\n",
    "\n",
    "#printStatsSVM(clf)\n",
    "#printROC(Y_dev, preds, 'ROC Curve - Support Vector Machines')\n",
    "# pick either rbf, adjust gamma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
